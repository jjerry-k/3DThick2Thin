{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm, time, random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import models, layers, losses, optimizers\n",
    "\n",
    "from loss import *\n",
    "from utils import *\n",
    "from network import *\n",
    "\n",
    "random.seed(777)\n",
    "tf.set_random_seed(777)\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../data/for_section/'\n",
    "\n",
    "fold_idx = 1\n",
    "\n",
    "train_path = os.path.join(root_dir, 'for_fold_%d'%fold_idx)\n",
    "\n",
    "val_path = os.path.join(root_dir, 'for_fold_%d_val'%fold_idx)\n",
    "\n",
    "total = data_loader(train_path)\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "n_size = 32\n",
    "n_slice = 16\n",
    "cs_strides = 16\n",
    "a_strides = 2\n",
    "\n",
    "#print(test.shape)\n",
    "\n",
    "for i in range(2):\n",
    "    test = total[i]\n",
    "    cor, sag, axi = test.shape\n",
    "    means = [test[idx:idx+n_size, jdx:jdx+n_size, kdx:kdx+(n_slice*6)].mean() \n",
    "             for idx in range(0, cor-n_size, cs_strides) \n",
    "             for jdx in range(0, sag-n_size, cs_strides) \n",
    "             for kdx in range(0, axi-(n_slice*6), a_strides)]\n",
    "\n",
    "\n",
    "    for idx in tqdm.tqdm_notebook(range(0, cor-n_size, cs_strides)):\n",
    "        for jdx in range(0, sag-n_size, cs_strides):\n",
    "            for kdx in range(0, axi-(n_slice*6), a_strides):\n",
    "                tmp = test[idx:idx+n_size, jdx:jdx+n_size, kdx:kdx+(n_slice*6)]\n",
    "                if tmp.mean() > np.mean(means)+10:\n",
    "                    label.append(tmp)\n",
    "                    tmp = np.array(np.dsplit(tmp, n_slice))\n",
    "                    tmp = tmp.mean(axis=-1)\n",
    "                    tmp = np.transpose(tmp, [1,2,0])\n",
    "                    data.append(tmp)\n",
    "                \n",
    "label = np.array(label)[..., np.newaxis]\n",
    "data = np.array(data)[..., np.newaxis]\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "\n",
    "\n",
    "# Prepare Validation\n",
    "val_data = []\n",
    "val_label = []\n",
    "\n",
    "# Prepare Validation\n",
    "scan_list = sorted(os.listdir(val_path))[1:3]\n",
    "for scan in scan_list:\n",
    "    dante_path = os.path.join(val_path, scan, 'T1SPACE09mmISOPOSTwDANTE')\n",
    "    img_name = [i for i in os.listdir(dante_path) if '.nii' in i and '_rsl' not in i][0]\n",
    "    #print(img_name)\n",
    "    val = nib.load(os.path.join(dante_path, img_name))\n",
    "    val = check_data(val.get_data())\n",
    "\n",
    "cor, sag, axi = test.shape\n",
    "#print(test.shape)\n",
    "for idx in tqdm.tqdm_notebook(range(0, cor-n_size, cs_strides)):\n",
    "    for jdx in range(0, sag-n_size, cs_strides):\n",
    "        for kdx in range(0, axi-(n_slice*6), a_strides):\n",
    "            tmp = val[idx:idx+n_size, jdx:jdx+n_size, kdx:kdx+(n_slice*6)]\n",
    "#             means.append(tmp.mean())\n",
    "            if tmp.mean() > 225:\n",
    "                val_label.append(tmp)\n",
    "                tmp = np.array(np.dsplit(tmp, n_slice))\n",
    "                tmp = tmp.mean(axis=-1)\n",
    "                tmp = np.transpose(tmp, [1,2,0])\n",
    "                val_data.append(tmp)\n",
    "                \n",
    "val_label = np.array(val_label)[..., np.newaxis]\n",
    "val_data = np.array(val_data)[..., np.newaxis]\n",
    "print(val_data.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SR3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.ctime().split(' ')\n",
    "\n",
    "ckpt_root = './checkpoint/%s_%02d_%s/DeepSR_msegrad_test'%(date[1], int(date[2]), date[-1])\n",
    "result_root = './result/%s_%02d_%s/DeepSR_msegrad_test'%(date[1], int(date[2]), date[-1])\n",
    "\n",
    "try:\n",
    "    os.makedirs(ckpt_root)\n",
    "    print(\"\\nMake Save Directory!\\n\")\n",
    "except:\n",
    "    print(\"\\nDirectory Already Exist!\\n\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(result_root)\n",
    "    print(\"\\nMake Save Directory!\\n\")\n",
    "except:\n",
    "    print(\"\\nDirectory Already Exist!\\n\")\n",
    "    \n",
    "\n",
    "model_json = net.to_json()\n",
    "with open(os.path.join(ckpt_root, \"model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"\\nModel Saved!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(optimizer=optimizers.Adam(0.0001), loss=mse_grad_loss, metrics=['mse', gradient_3d_loss, mutual_information])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.fit(data, label, batch_size=16, epochs=100, validation_data=[val_data, val_label])\n",
    "\n",
    "net.save_weights(os.path.join(ckpt_root, 'weight.h5'))\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(os.path.join(result_root, 'loss.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_list = sorted(os.listdir(val_path))[1:]\n",
    "for scan in scan_list:\n",
    "    dante_path = os.path.join(val_path, scan, 'T1SPACE09mmISOPOSTwDANTE')\n",
    "    img_name = [i for i in os.listdir(dante_path) if '.nii' in i and '_rsl' not in i][0]\n",
    "    #print(img_name)\n",
    "    val = nib.load(os.path.join(dante_path, img_name))\n",
    "    val = check_data(val.get_data())\n",
    "    \n",
    "val_in = []\n",
    "cor, sag, axi = val.shape\n",
    "tmp = np.array(np.dsplit(val, axi//6))\n",
    "tmp = tmp.mean(axis=-1)\n",
    "tmp = np.transpose(tmp, [1, 2, 0])\n",
    "\n",
    "half_top = int(np.floor(tmp.shape[-1]/2))\n",
    "#half_bot = int(np.ceil(tmp.shape[-1]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = np.zeros(shape=[cor, sag, axi])\n",
    "\n",
    "slice_dict = {\n",
    "    1:[[0, 160], [0, 160], [0, 128], [0, 128]], \n",
    "    2:[[0, 160], [96, 256], [0, 128], [32, 256]], \n",
    "    3:[[96, 256], [0, 160], [32, 256], [0, 128]],\n",
    "    4:[[96, 256], [96, 256], [32, 256], [32, 256]]\n",
    "}\n",
    "test = {}\n",
    "sli = 12\n",
    "i = 0\n",
    "for row in range(2):\n",
    "    row_start = row*128\n",
    "    for col in range(2):\n",
    "        \n",
    "        col_start = col*128\n",
    "        print(i, row_start, col_start)\n",
    "        test[i] = net.predict(tmp[np.newaxis, \n",
    "                                   slice_dict[i+1][0][0]:slice_dict[i+1][0][1],\n",
    "                                   slice_dict[i+1][1][0]:slice_dict[i+1][1][1],\n",
    "                                   :, np.newaxis])\n",
    "        recon[row_start:row_start+128, \n",
    "              col_start:col_start+128] = test[i][0,\n",
    "                                                  slice_dict[i+1][2][0]:slice_dict[i+1][2][1],\n",
    "                                                  slice_dict[i+1][3][0]:slice_dict[i+1][3][1], :, 0]\n",
    "        i += 1\n",
    "# test_3d_2 = net.predict(tmp[np.newaxis, ..., half_top:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = np.eye(4)\n",
    "aff[2, 2]=6\n",
    "\n",
    "nib.save(nib.Nifti1Image(tmp, aff), os.path.join(result_root, 'val_input.nii'))\n",
    "nib.save(nib.Nifti1Image(recon, np.eye(4)), os.path.join(result_root, 'val_pred.nii'))\n",
    "nib.save(nib.Nifti1Image(val, np.eye(4)), os.path.join(result_root, 'val_label.nii'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
